{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609fc817-5466-4f95-911c-5612137cf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffadbee-6acc-446b-8eea-fb6c84e743c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90c5ff5-654b-497d-86db-0f83aa0cdb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen =  ImageDataGenerator(rescale=1./255,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897e056c-edd9-42fe-b5e4-ac54315ddfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen =  ImageDataGenerator(rescale=1./255,)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35312c3-5730-4bcd-936d-34ce7374ad31",
   "metadata": {},
   "source": [
    "**Initialsing the CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9f37a7-c0e7-4537-bdc4-b4c4a73e0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c039d1c-ab7e-46a9-842d-165ed9edbb6b",
   "metadata": {},
   "source": [
    "**Convulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99ddcda-d0e0-43eb-9365-840d8c7e9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657540b-34a7-4a5b-aa6a-61e35940634f",
   "metadata": {},
   "source": [
    "**Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "908f5f81-41f2-45c5-977b-a02fc192cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa4ff7-d479-4440-8b5a-9bcdb533d075",
   "metadata": {},
   "source": [
    "**Second CNN layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8da4e1-6612-44a6-9c83-09d36dbe0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72efb8cf-126c-4c07-9473-6ad2b72d6b8e",
   "metadata": {},
   "source": [
    "**Flatteing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56e292f0-a43f-4cd7-8b11-004993764d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3e114-cbfc-4349-a007-61a7a5d8451f",
   "metadata": {},
   "source": [
    "**Full Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5febbb1f-432a-49ca-a410-4409a388f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units = 128, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3efe5dc-2b8f-4a77-b4ca-e81f20daa79c",
   "metadata": {},
   "source": [
    "**output layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ca079bd-b97d-4e74-b1c3-b6ae945929f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a90fd-81cf-4f8f-858e-631f107ca848",
   "metadata": {},
   "source": [
    "**compiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1426fefa-4853-4e0b-888b-e3a0b7626ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5071f-e33b-42d7-bb48-a8ecd1b05409",
   "metadata": {},
   "source": [
    "**Training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "798a1325-3ea6-4503-84cb-9372426b5693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 760ms/step - Accuracy: 0.5581 - loss: 0.6771 - val_Accuracy: 0.6915 - val_loss: 0.5909\n",
      "Epoch 2/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 334ms/step - Accuracy: 0.6817 - loss: 0.5993 - val_Accuracy: 0.6880 - val_loss: 0.6018\n",
      "Epoch 3/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 328ms/step - Accuracy: 0.7153 - loss: 0.5573 - val_Accuracy: 0.7545 - val_loss: 0.5012\n",
      "Epoch 4/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 323ms/step - Accuracy: 0.7441 - loss: 0.5229 - val_Accuracy: 0.7455 - val_loss: 0.5249\n",
      "Epoch 5/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 321ms/step - Accuracy: 0.7549 - loss: 0.5024 - val_Accuracy: 0.7505 - val_loss: 0.5018\n",
      "Epoch 6/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 325ms/step - Accuracy: 0.7810 - loss: 0.4650 - val_Accuracy: 0.7870 - val_loss: 0.4476\n",
      "Epoch 7/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 322ms/step - Accuracy: 0.7848 - loss: 0.4551 - val_Accuracy: 0.7820 - val_loss: 0.4829\n",
      "Epoch 8/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 177ms/step - Accuracy: 0.7998 - loss: 0.4331 - val_Accuracy: 0.8090 - val_loss: 0.4190\n",
      "Epoch 9/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 174ms/step - Accuracy: 0.8062 - loss: 0.4127 - val_Accuracy: 0.8250 - val_loss: 0.3952\n",
      "Epoch 10/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 194ms/step - Accuracy: 0.8181 - loss: 0.4068 - val_Accuracy: 0.8170 - val_loss: 0.4098\n",
      "Epoch 11/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 167ms/step - Accuracy: 0.8186 - loss: 0.3973 - val_Accuracy: 0.8100 - val_loss: 0.4316\n",
      "Epoch 12/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 183ms/step - Accuracy: 0.8176 - loss: 0.3869 - val_Accuracy: 0.8170 - val_loss: 0.4103\n",
      "Epoch 13/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 185ms/step - Accuracy: 0.8433 - loss: 0.3582 - val_Accuracy: 0.7995 - val_loss: 0.4414\n",
      "Epoch 14/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 187ms/step - Accuracy: 0.8368 - loss: 0.3574 - val_Accuracy: 0.8150 - val_loss: 0.4108\n",
      "Epoch 15/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 185ms/step - Accuracy: 0.8429 - loss: 0.3415 - val_Accuracy: 0.8445 - val_loss: 0.3609\n",
      "Epoch 16/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - Accuracy: 0.8534 - loss: 0.3269 - val_Accuracy: 0.8210 - val_loss: 0.4304\n",
      "Epoch 17/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 191ms/step - Accuracy: 0.8524 - loss: 0.3281 - val_Accuracy: 0.8385 - val_loss: 0.3975\n",
      "Epoch 18/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 167ms/step - Accuracy: 0.8634 - loss: 0.3130 - val_Accuracy: 0.8195 - val_loss: 0.4048\n",
      "Epoch 19/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - Accuracy: 0.8560 - loss: 0.3106 - val_Accuracy: 0.8180 - val_loss: 0.4014\n",
      "Epoch 20/20\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 243ms/step - Accuracy: 0.8704 - loss: 0.3014 - val_Accuracy: 0.8610 - val_loss: 0.3680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fddec81e90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44cef636-93c3-4eef-8ee7-644e1269e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440567b5-8009-492e-bcf8-828f1080f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size =(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e9768e-67ed-46cb-8786-301bae4b61a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "result = cnn.predict(test_image)\n",
    "\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4bc68a2-d0ab-4d32-bb91-8b0def4788f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50d941-0c03-4a4c-a517-bfc73b9f5f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
